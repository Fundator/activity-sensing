{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from tcn import tcn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 9)\n",
      "(4500, 9)\n",
      "(9000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>mag_x</th>\n",
       "      <th>mag_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.935</td>\n",
       "      <td>-5.104</td>\n",
       "      <td>0.690</td>\n",
       "      <td>3.069</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.579</td>\n",
       "      <td>-15.125</td>\n",
       "      <td>58.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.784</td>\n",
       "      <td>-7.403</td>\n",
       "      <td>3.266</td>\n",
       "      <td>2.771</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>0.390</td>\n",
       "      <td>-13.813</td>\n",
       "      <td>56.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.881</td>\n",
       "      <td>-5.650</td>\n",
       "      <td>5.104</td>\n",
       "      <td>2.677</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-14.000</td>\n",
       "      <td>53.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019</td>\n",
       "      <td>-3.792</td>\n",
       "      <td>7.518</td>\n",
       "      <td>2.652</td>\n",
       "      <td>-1.042</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-12.813</td>\n",
       "      <td>48.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163</td>\n",
       "      <td>-2.835</td>\n",
       "      <td>8.389</td>\n",
       "      <td>2.376</td>\n",
       "      <td>-1.106</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-13.750</td>\n",
       "      <td>41.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.025</td>\n",
       "      <td>-2.145</td>\n",
       "      <td>9.318</td>\n",
       "      <td>2.195</td>\n",
       "      <td>-1.017</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-16.125</td>\n",
       "      <td>34.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.766</td>\n",
       "      <td>0.124</td>\n",
       "      <td>10.218</td>\n",
       "      <td>1.957</td>\n",
       "      <td>-1.172</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-17.063</td>\n",
       "      <td>27.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.398</td>\n",
       "      <td>0.555</td>\n",
       "      <td>10.898</td>\n",
       "      <td>1.005</td>\n",
       "      <td>-0.634</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-20.938</td>\n",
       "      <td>17.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.538</td>\n",
       "      <td>2.950</td>\n",
       "      <td>11.837</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-22.500</td>\n",
       "      <td>11.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.026</td>\n",
       "      <td>4.070</td>\n",
       "      <td>13.819</td>\n",
       "      <td>-1.679</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.639</td>\n",
       "      <td>-26.250</td>\n",
       "      <td>5.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.112</td>\n",
       "      <td>3.687</td>\n",
       "      <td>13.475</td>\n",
       "      <td>-2.822</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-27.750</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.662</td>\n",
       "      <td>1.666</td>\n",
       "      <td>10.812</td>\n",
       "      <td>-3.011</td>\n",
       "      <td>1.421</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-28.500</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.862</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>10.602</td>\n",
       "      <td>-2.717</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-28.375</td>\n",
       "      <td>3.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.565</td>\n",
       "      <td>-3.026</td>\n",
       "      <td>9.424</td>\n",
       "      <td>-2.641</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-23.938</td>\n",
       "      <td>10.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.517</td>\n",
       "      <td>-4.214</td>\n",
       "      <td>8.265</td>\n",
       "      <td>-2.811</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-20.813</td>\n",
       "      <td>20.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.354</td>\n",
       "      <td>-5.871</td>\n",
       "      <td>7.374</td>\n",
       "      <td>-2.988</td>\n",
       "      <td>0.209</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-19.188</td>\n",
       "      <td>26.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-8.715</td>\n",
       "      <td>4.338</td>\n",
       "      <td>-2.942</td>\n",
       "      <td>0.502</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-18.938</td>\n",
       "      <td>34.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.134</td>\n",
       "      <td>-9.481</td>\n",
       "      <td>2.174</td>\n",
       "      <td>-2.610</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-18.688</td>\n",
       "      <td>41.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.632</td>\n",
       "      <td>-6.608</td>\n",
       "      <td>1.120</td>\n",
       "      <td>-2.062</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-18.438</td>\n",
       "      <td>48.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-6.110</td>\n",
       "      <td>0.613</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-19.000</td>\n",
       "      <td>51.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.326</td>\n",
       "      <td>-9.864</td>\n",
       "      <td>2.442</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-18.063</td>\n",
       "      <td>57.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.034</td>\n",
       "      <td>-11.741</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-16.563</td>\n",
       "      <td>59.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.967</td>\n",
       "      <td>-9.251</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-16.500</td>\n",
       "      <td>59.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.402</td>\n",
       "      <td>-9.960</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-17.250</td>\n",
       "      <td>58.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.460</td>\n",
       "      <td>-9.979</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-16.500</td>\n",
       "      <td>59.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.547</td>\n",
       "      <td>-9.510</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-16.563</td>\n",
       "      <td>57.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.077</td>\n",
       "      <td>-9.826</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-16.563</td>\n",
       "      <td>57.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.594</td>\n",
       "      <td>-9.653</td>\n",
       "      <td>-1.025</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-18.688</td>\n",
       "      <td>59.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.086</td>\n",
       "      <td>-10.381</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-16.625</td>\n",
       "      <td>56.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.048</td>\n",
       "      <td>-10.372</td>\n",
       "      <td>-1.293</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>-18.688</td>\n",
       "      <td>58.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8970</th>\n",
       "      <td>2.298</td>\n",
       "      <td>3.496</td>\n",
       "      <td>-8.121</td>\n",
       "      <td>1.757</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>2.470</td>\n",
       "      <td>12.375</td>\n",
       "      <td>39.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>2.433</td>\n",
       "      <td>3.371</td>\n",
       "      <td>-8.131</td>\n",
       "      <td>2.517</td>\n",
       "      <td>-0.717</td>\n",
       "      <td>2.547</td>\n",
       "      <td>11.063</td>\n",
       "      <td>43.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>2.423</td>\n",
       "      <td>3.170</td>\n",
       "      <td>-8.341</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>2.609</td>\n",
       "      <td>11.875</td>\n",
       "      <td>46.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>2.088</td>\n",
       "      <td>3.170</td>\n",
       "      <td>-9.625</td>\n",
       "      <td>2.194</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>1.826</td>\n",
       "      <td>7.063</td>\n",
       "      <td>49.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8974</th>\n",
       "      <td>2.011</td>\n",
       "      <td>2.356</td>\n",
       "      <td>-10.841</td>\n",
       "      <td>2.531</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>1.199</td>\n",
       "      <td>6.375</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>1.896</td>\n",
       "      <td>2.576</td>\n",
       "      <td>-9.644</td>\n",
       "      <td>2.385</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>1.302</td>\n",
       "      <td>7.063</td>\n",
       "      <td>49.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>2.892</td>\n",
       "      <td>2.739</td>\n",
       "      <td>-8.657</td>\n",
       "      <td>2.262</td>\n",
       "      <td>-1.209</td>\n",
       "      <td>1.041</td>\n",
       "      <td>8.313</td>\n",
       "      <td>46.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>4.089</td>\n",
       "      <td>1.791</td>\n",
       "      <td>-8.447</td>\n",
       "      <td>1.979</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.125</td>\n",
       "      <td>41.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>3.658</td>\n",
       "      <td>2.049</td>\n",
       "      <td>-9.692</td>\n",
       "      <td>2.018</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>1.234</td>\n",
       "      <td>11.563</td>\n",
       "      <td>36.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>3.783</td>\n",
       "      <td>2.021</td>\n",
       "      <td>-9.998</td>\n",
       "      <td>2.036</td>\n",
       "      <td>-1.275</td>\n",
       "      <td>1.327</td>\n",
       "      <td>11.313</td>\n",
       "      <td>27.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>4.683</td>\n",
       "      <td>1.389</td>\n",
       "      <td>-9.759</td>\n",
       "      <td>1.624</td>\n",
       "      <td>-1.612</td>\n",
       "      <td>0.727</td>\n",
       "      <td>9.500</td>\n",
       "      <td>16.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>5.449</td>\n",
       "      <td>1.599</td>\n",
       "      <td>-8.514</td>\n",
       "      <td>1.415</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>0.368</td>\n",
       "      <td>4.375</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>4.702</td>\n",
       "      <td>3.438</td>\n",
       "      <td>-3.888</td>\n",
       "      <td>0.934</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>0.527</td>\n",
       "      <td>2.813</td>\n",
       "      <td>2.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>4.846</td>\n",
       "      <td>2.605</td>\n",
       "      <td>-4.769</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>-4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>3.773</td>\n",
       "      <td>3.189</td>\n",
       "      <td>-2.950</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>-3.938</td>\n",
       "      <td>-11.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>4.348</td>\n",
       "      <td>2.978</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-1.689</td>\n",
       "      <td>1.066</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>-8.938</td>\n",
       "      <td>-13.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>3.342</td>\n",
       "      <td>2.873</td>\n",
       "      <td>2.337</td>\n",
       "      <td>-2.398</td>\n",
       "      <td>1.180</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>-12.625</td>\n",
       "      <td>-17.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>2.758</td>\n",
       "      <td>4.817</td>\n",
       "      <td>8.131</td>\n",
       "      <td>-1.671</td>\n",
       "      <td>1.220</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-16.188</td>\n",
       "      <td>-21.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>3.725</td>\n",
       "      <td>3.601</td>\n",
       "      <td>8.083</td>\n",
       "      <td>-1.887</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-21.125</td>\n",
       "      <td>-22.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>0.038</td>\n",
       "      <td>5.832</td>\n",
       "      <td>10.851</td>\n",
       "      <td>-2.282</td>\n",
       "      <td>0.589</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-22.500</td>\n",
       "      <td>-21.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>1.733</td>\n",
       "      <td>3.122</td>\n",
       "      <td>10.582</td>\n",
       "      <td>-2.252</td>\n",
       "      <td>0.779</td>\n",
       "      <td>-0.534</td>\n",
       "      <td>-23.188</td>\n",
       "      <td>-21.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>1.255</td>\n",
       "      <td>0.891</td>\n",
       "      <td>13.273</td>\n",
       "      <td>-3.594</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-24.563</td>\n",
       "      <td>-21.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>1.331</td>\n",
       "      <td>-1.753</td>\n",
       "      <td>13.695</td>\n",
       "      <td>-2.574</td>\n",
       "      <td>1.683</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-25.313</td>\n",
       "      <td>-21.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8993</th>\n",
       "      <td>2.021</td>\n",
       "      <td>-4.223</td>\n",
       "      <td>15.151</td>\n",
       "      <td>-4.148</td>\n",
       "      <td>1.248</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-23.875</td>\n",
       "      <td>-21.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>-1.120</td>\n",
       "      <td>-2.940</td>\n",
       "      <td>7.365</td>\n",
       "      <td>-1.096</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-22.500</td>\n",
       "      <td>-22.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>-1.781</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>5.258</td>\n",
       "      <td>-1.899</td>\n",
       "      <td>0.907</td>\n",
       "      <td>-1.074</td>\n",
       "      <td>-20.438</td>\n",
       "      <td>-22.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>1.398</td>\n",
       "      <td>-4.999</td>\n",
       "      <td>2.567</td>\n",
       "      <td>-1.553</td>\n",
       "      <td>0.753</td>\n",
       "      <td>-0.796</td>\n",
       "      <td>-19.750</td>\n",
       "      <td>-20.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>0.661</td>\n",
       "      <td>-6.177</td>\n",
       "      <td>3.457</td>\n",
       "      <td>-0.826</td>\n",
       "      <td>1.090</td>\n",
       "      <td>-1.855</td>\n",
       "      <td>-19.750</td>\n",
       "      <td>-17.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>1.915</td>\n",
       "      <td>-7.757</td>\n",
       "      <td>5.851</td>\n",
       "      <td>-1.096</td>\n",
       "      <td>1.561</td>\n",
       "      <td>-2.271</td>\n",
       "      <td>-18.250</td>\n",
       "      <td>-15.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>1.101</td>\n",
       "      <td>-8.859</td>\n",
       "      <td>4.492</td>\n",
       "      <td>-1.810</td>\n",
       "      <td>1.380</td>\n",
       "      <td>-2.150</td>\n",
       "      <td>-16.063</td>\n",
       "      <td>-11.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_x   acc_y   acc_z  gyro_x  gyro_y  gyro_z   mag_x   mag_y\n",
       "0     1.935  -5.104   0.690   3.069   0.177   0.579 -15.125  58.500\n",
       "1    -5.784  -7.403   3.266   2.771  -0.469   0.390 -13.813  56.500\n",
       "2    -0.881  -5.650   5.104   2.677  -0.504  -0.155 -14.000  53.063\n",
       "3     0.019  -3.792   7.518   2.652  -1.042  -0.089 -12.813  48.250\n",
       "4     0.163  -2.835   8.389   2.376  -1.106  -0.100 -13.750  41.938\n",
       "5    -1.025  -2.145   9.318   2.195  -1.017  -0.303 -16.125  34.188\n",
       "6     0.766   0.124  10.218   1.957  -1.172  -0.411 -17.063  27.188\n",
       "7     1.398   0.555  10.898   1.005  -0.634  -0.366 -20.938  17.313\n",
       "8     2.538   2.950  11.837  -0.210   0.196   0.181 -22.500  11.688\n",
       "9     3.026   4.070  13.819  -1.679   0.627   0.639 -26.250   5.250\n",
       "10    3.112   3.687  13.475  -2.822   1.200   0.471 -27.750   1.000\n",
       "11    2.662   1.666  10.812  -3.011   1.421   0.244 -28.500   1.000\n",
       "12    0.862  -0.642  10.602  -2.717   0.869   0.102 -28.375   3.813\n",
       "13   -0.565  -3.026   9.424  -2.641   0.394  -0.165 -23.938  10.875\n",
       "14   -0.517  -4.214   8.265  -2.811   0.144  -0.246 -20.813  20.063\n",
       "15   -0.354  -5.871   7.374  -2.988   0.209  -0.270 -19.188  26.438\n",
       "16    0.010  -8.715   4.338  -2.942   0.502  -0.165 -18.938  34.125\n",
       "17   -0.134  -9.481   2.174  -2.610   0.970   0.128 -18.688  41.063\n",
       "18   -0.632  -6.608   1.120  -2.062   1.030   0.173 -18.438  48.063\n",
       "19    0.000  -6.110   0.613  -0.912  -0.020  -0.244 -19.000  51.500\n",
       "20    0.326  -9.864   2.442   0.077   0.119  -0.078 -18.063  57.063\n",
       "21   -1.034 -11.741   0.259   0.177   0.161  -0.016 -16.563  59.188\n",
       "22   -0.967  -9.251   0.441   0.026   0.274  -0.083 -16.500  59.125\n",
       "23    0.402  -9.960  -0.096   0.130   0.372  -0.116 -17.250  58.438\n",
       "24   -0.460  -9.979   0.306  -0.009  -0.248   0.046 -16.500  59.188\n",
       "25   -2.547  -9.510   0.402   0.015  -0.677   0.016 -16.563  57.750\n",
       "26   -0.077  -9.826   0.690   0.138  -0.467   0.069 -16.563  57.750\n",
       "27   -0.594  -9.653  -1.025   0.327  -0.113   0.051 -18.688  59.125\n",
       "28    0.086 -10.381   0.498   0.454   0.379   0.040 -16.625  56.375\n",
       "29   -0.048 -10.372  -1.293  -0.135  -0.130  -0.840 -18.688  58.375\n",
       "...     ...     ...     ...     ...     ...     ...     ...     ...\n",
       "8970  2.298   3.496  -8.121   1.757  -0.210   2.470  12.375  39.000\n",
       "8971  2.433   3.371  -8.131   2.517  -0.717   2.547  11.063  43.875\n",
       "8972  2.423   3.170  -8.341   2.078  -0.763   2.609  11.875  46.625\n",
       "8973  2.088   3.170  -9.625   2.194  -0.375   1.826   7.063  49.313\n",
       "8974  2.011   2.356 -10.841   2.531  -0.206   1.199   6.375  50.000\n",
       "8975  1.896   2.576  -9.644   2.385  -1.277   1.302   7.063  49.313\n",
       "8976  2.892   2.739  -8.657   2.262  -1.209   1.041   8.313  46.563\n",
       "8977  4.089   1.791  -8.447   1.979  -0.927   1.000   8.125  41.688\n",
       "8978  3.658   2.049  -9.692   2.018  -0.666   1.234  11.563  36.875\n",
       "8979  3.783   2.021  -9.998   2.036  -1.275   1.327  11.313  27.813\n",
       "8980  4.683   1.389  -9.759   1.624  -1.612   0.727   9.500  16.563\n",
       "8981  5.449   1.599  -8.514   1.415  -0.883   0.368   4.375   8.000\n",
       "8982  4.702   3.438  -3.888   0.934  -0.866   0.527   2.813   2.375\n",
       "8983  4.846   2.605  -4.769   0.025  -0.596   0.426  -0.188  -4.000\n",
       "8984  3.773   3.189  -2.950  -0.918   0.165  -0.591  -3.938 -11.125\n",
       "8985  4.348   2.978   0.201  -1.689   1.066  -0.897  -8.938 -13.438\n",
       "8986  3.342   2.873   2.337  -2.398   1.180  -0.615 -12.625 -17.750\n",
       "8987  2.758   4.817   8.131  -1.671   1.220  -0.118 -16.188 -21.375\n",
       "8988  3.725   3.601   8.083  -1.887   0.389   0.132 -21.125 -22.250\n",
       "8989  0.038   5.832  10.851  -2.282   0.589  -0.241 -22.500 -21.625\n",
       "8990  1.733   3.122  10.582  -2.252   0.779  -0.534 -23.188 -21.688\n",
       "8991  1.255   0.891  13.273  -3.594   0.269  -0.037 -24.563 -21.750\n",
       "8992  1.331  -1.753  13.695  -2.574   1.683   0.062 -25.313 -21.750\n",
       "8993  2.021  -4.223  15.151  -4.148   1.248  -0.956 -23.875 -21.000\n",
       "8994 -1.120  -2.940   7.365  -1.096   0.201  -0.642 -22.500 -22.313\n",
       "8995 -1.781  -2.624   5.258  -1.899   0.907  -1.074 -20.438 -22.188\n",
       "8996  1.398  -4.999   2.567  -1.553   0.753  -0.796 -19.750 -20.750\n",
       "8997  0.661  -6.177   3.457  -0.826   1.090  -1.855 -19.750 -17.938\n",
       "8998  1.915  -7.757   5.851  -1.096   1.561  -2.271 -18.250 -15.063\n",
       "8999  1.101  -8.859   4.492  -1.810   1.380  -2.150 -16.063 -11.500\n",
       "\n",
       "[9000 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for i in range(3,6):\n",
    "    df = pd.read_pickle(\"data/df_MB_\"+str(i))\n",
    "    df.drop(\"sensor\", axis=1, inplace=True)\n",
    "    dfs.append(df)\n",
    "\n",
    "train = pd.concat(dfs, axis=1)\n",
    "print(train.shape)\n",
    "train.columns = [sensor+m for sensor in [\"acc_\", \"gyro_\", \"mag_\"] for m in [\"x\", \"y\", \"z\"]]\n",
    "#train[\"y\"] = 0\n",
    "\n",
    "#dfs = []\n",
    "#for i in range(3,6):\n",
    "#    df = pd.read_pickle(\"data/df_not_squats_\"+str(i))\n",
    "#    df.drop(\"sensor\", axis=1, inplace=True)\n",
    "#    dfs.append(df)\n",
    "\n",
    "train2 = pd.read_pickle(\"data/df_negative\") #pd.concat(dfs, axis=1)\n",
    "train2[\"mag_z\"] = 0\n",
    "train2 = train2.iloc[:4500]\n",
    "train2.columns = [sensor+m for sensor in [\"acc_\", \"gyro_\", \"mag_\"] for m in [\"x\", \"y\", \"z\"]]\n",
    "#train2[\"y\"] = 1\n",
    "print(train2.shape)\n",
    "train = pd.concat([train,train2], ignore_index=True, axis=0)\n",
    "print(train.shape)\n",
    "train.drop(\"mag_z\", axis=1, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.fillna(method=\"pad\", inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sc = sc.fit_transform(train.values.astype(\"float\"))\n",
    "train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pos = new_df.iloc[:4500]\n",
    "df_neg = new_df.iloc[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_samples = []\n",
    "neg_samples = []\n",
    "for i in range(len(df_pos)-45):\n",
    "    pos = df_pos.iloc[i:i+45].values\n",
    "    neg = df_neg.iloc[i:i+45].values\n",
    "    pos_samples.append(pos)\n",
    "    neg_samples.append(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4455, 45, 8), (4455, 45, 8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pos = np.stack(pos_samples)\n",
    "X_neg = np.stack(neg_samples)\n",
    "X_pos.shape, X_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8910, 45, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([X_pos, X_neg], axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.zeros(len(X))\n",
    "y[:4455] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = np.array_split(train_sc, len(train)/45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.stack(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 45, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.zeros(len(X))\n",
    "y[:100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7128, 45, 8), (1782, 45, 8), (7128,), (1782,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape= (?, 8)\n",
      "model.x = (?, 45, 8)\n",
      "model.y = (?, 2)\n",
      "Adam with norm clipping.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        (None, 45, 8)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "initial_conv (Conv1D)           (None, 45, 8)        264         input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_tanh_s0 (Conv1D) (None, 45, 8)        264         initial_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 45, 8)        0           dilated_conv_2_tanh_s0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 45, 8)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 45, 8)        0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 45, 8)        0           initial_conv[0][0]               \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_tanh_s0 (Conv1D) (None, 45, 8)        264         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 45, 8)        0           dilated_conv_4_tanh_s0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 45, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 45, 8)        0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 45, 8)        0           add_1[0][0]                      \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_tanh_s0 (Conv1D (None, 45, 8)        264         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 45, 8)        0           dilated_conv_16_tanh_s0[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 45, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 45, 8)        0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 45, 8)        0           add_2[0][0]                      \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_tanh_s0 (Conv1 (None, 45, 8)        264         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 45, 8)        0           dilated_conv_256_tanh_s0[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 45, 8)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 45, 8)        0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 45, 8)        0           add_3[0][0]                      \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_tanh_s1 (Conv1D) (None, 45, 8)        264         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 45, 8)        0           dilated_conv_2_tanh_s1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 45, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 45, 8)        0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 45, 8)        0           add_4[0][0]                      \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_tanh_s1 (Conv1D) (None, 45, 8)        264         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 45, 8)        0           dilated_conv_4_tanh_s1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 45, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 45, 8)        0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 45, 8)        0           add_5[0][0]                      \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_tanh_s1 (Conv1D (None, 45, 8)        264         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 45, 8)        0           dilated_conv_16_tanh_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 45, 8)        0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 45, 8)        0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 45, 8)        0           add_6[0][0]                      \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_tanh_s1 (Conv1 (None, 45, 8)        264         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 45, 8)        0           dilated_conv_256_tanh_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 45, 8)        0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 45, 8)        0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 45, 8)        0           add_7[0][0]                      \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_tanh_s2 (Conv1D) (None, 45, 8)        264         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 45, 8)        0           dilated_conv_2_tanh_s2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 45, 8)        0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 45, 8)        0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 45, 8)        72          spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 45, 8)        0           add_8[0][0]                      \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_tanh_s2 (Conv1D) (None, 45, 8)        264         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 45, 8)        0           dilated_conv_4_tanh_s2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 45, 8)        0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 45, 8)        0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 45, 8)        72          spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 45, 8)        0           add_9[0][0]                      \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_tanh_s2 (Conv1D (None, 45, 8)        264         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 45, 8)        0           dilated_conv_16_tanh_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 45, 8)        0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 45, 8)        0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 45, 8)        72          spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 45, 8)        0           add_10[0][0]                     \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_tanh_s2 (Conv1 (None, 45, 8)        264         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 45, 8)        0           dilated_conv_256_tanh_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 45, 8)        0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 45, 8)        0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 45, 8)        72          spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 45, 8)        0           add_11[0][0]                     \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_tanh_s3 (Conv1D) (None, 45, 8)        264         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 45, 8)        0           dilated_conv_2_tanh_s3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 45, 8)        0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 45, 8)        0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 45, 8)        72          spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 45, 8)        0           add_12[0][0]                     \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_tanh_s3 (Conv1D) (None, 45, 8)        264         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 45, 8)        0           dilated_conv_4_tanh_s3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 45, 8)        0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 45, 8)        0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 45, 8)        72          spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 45, 8)        0           add_13[0][0]                     \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_tanh_s3 (Conv1D (None, 45, 8)        264         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 45, 8)        0           dilated_conv_16_tanh_s3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 45, 8)        0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 45, 8)        0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 45, 8)        72          spatial_dropout1d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 45, 8)        0           add_14[0][0]                     \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_256_tanh_s3 (Conv1 (None, 45, 8)        264         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 45, 8)        0           dilated_conv_256_tanh_s3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 45, 8)        0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 45, 8)        0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 45, 8)        72          spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 45, 8)        0           add_15[0][0]                     \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 45, 8)        0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 8)            0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            18          lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_softmax (Activation)     (None, 2)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,658\n",
      "Trainable params: 5,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, param_str = tcn.dilated_tcn(output_slice_index='last', # try 'first'.\n",
    "                                       num_feat=8,\n",
    "                                       num_classes=2,\n",
    "                                       nb_filters=8,\n",
    "                                       kernel_size=4,\n",
    "                                       dilatations=[1, 2, 4, 8],\n",
    "                                       nb_stacks=4,\n",
    "                                       max_len=45,\n",
    "                                       activation='norm_relu',\n",
    "                                       use_skip_connections=False,\n",
    "                                       return_param_str=True)\n",
    "\n",
    "#print(f'x_train.shape = {x_train.shape}')\n",
    "#print(f'y_train.shape = {y_train.shape}')\n",
    "# Using sparse softmax.\n",
    "# http://chappers.github.io/web%20micro%20log/2017/01/26/quick-models-in-keras/\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7128 samples, validate on 1782 samples\n",
      "Epoch 1/2\n",
      "7128/7128 [==============================] - 4s 607us/step - loss: 0.0254 - acc: 0.9917 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "7128/7128 [==============================] - 4s 573us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 6.1982e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f90b41aaeb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          epochs=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model, save_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model,'squat_detector_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9999714e-01, 2.8914906e-06]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[17:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(sc, open(\"data/sc_3.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# Start the server:\n",
    "# \tpython run_keras_server.py\n",
    "# Submit a request via cURL:\n",
    "# \tcurl -X POST -F image=@dog.jpg 'http://localhost:5000/predict'\n",
    "# Submita a request via Python:\n",
    "#\tpython simple_request.py\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import flask\n",
    "import io\n",
    "\n",
    "# initialize our Flask application and the Keras model\n",
    "app = flask.Flask(__name__)\n",
    "model = None\n",
    "\n",
    "\n",
    "\n",
    "def load_model():\n",
    "\t# load the pre-trained Keras model (here we are using a model\n",
    "\t# pre-trained on ImageNet and provided by Keras, but you can\n",
    "\t# substitute in your own networks just as easily)\n",
    "\tglobal model\n",
    "\tmodel = load_model('squat_detector.h5') #ResNet50(weights=\"imagenet\")\n",
    "\n",
    "    \n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "\t# initialize the data dictionary that will be returned from the\n",
    "\t# view\n",
    "\tdata = {\"success\": False, \"squat_prob\":None}\n",
    "\n",
    "\t# ensure an image was properly uploaded to our endpoint\n",
    "\tif flask.request.method == \"POST\":\n",
    "\t\tif flask.request.files.get(\"input\"):\n",
    "\t\t\t# read the image in PIL format\n",
    "\t\t\tx_b = flask.request.files[\"input\"].read()\n",
    "\t\t\tx = np.frombuffer(x)\n",
    "            squat_prob = model.predict(x)[0][1]\n",
    "\t\t\t# indicate that the request was a success\n",
    "            data[\"squat_prob\"] = squat_prob\n",
    "\t\t\tdata[\"success\"] = True\n",
    "\n",
    "\t# return the data dictionary as a JSON response\n",
    "\treturn flask.jsonify(data)\n",
    "\n",
    "# if this is the main thread of execution first load the model and\n",
    "# then start the server\n",
    "if __name__ == \"__main__\":\n",
    "\tprint((\"* Loading Keras model and Flask starting server...\"\n",
    "\t\t\"please wait until server has fully started\"))\n",
    "\tload_model()\n",
    "\tapp.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
